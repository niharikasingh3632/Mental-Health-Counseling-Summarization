{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt0wzbakhFwXTdOPoKPKCC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niharikasingh3632/Mental-Health-Counseling-Summarization/blob/main/Processing_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZh1l5ohkbNE",
        "outputId": "3b0ecc9d-d581-4c38-e553-61fea73f83ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy inflect\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufV6csmyxcj3",
        "outputId": "400899f5-74b2-4e02-aef4-1da1842da748"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (7.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect) (4.4.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import inflect\n",
        "\n",
        "# Load NLP tools\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "inflect_engine = inflect.engine()\n",
        "\n",
        "def adjust_utterance(text, role):\n",
        "    doc = nlp(text)\n",
        "    new_tokens = []\n",
        "    skip_next = False\n",
        "\n",
        "    for i, token in enumerate(doc):\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue\n",
        "\n",
        "        if token.text.lower() in [\"i'm\"]:\n",
        "            new_tokens.append(role)\n",
        "            continue\n",
        "\n",
        "        if token.text.lower() == \"i\":\n",
        "            new_tokens.append(role)\n",
        "            if i + 1 < len(doc):\n",
        "                next_token = doc[i + 1]\n",
        "                if next_token.tag_ == \"VBP\":\n",
        "                    corrected = inflect_engine.plural_verb(next_token.text)\n",
        "                    new_tokens.append(corrected)\n",
        "                    skip_next = True\n",
        "            continue\n",
        "\n",
        "        new_tokens.append(token.text)\n",
        "\n",
        "    return \" \".join(new_tokens)\n",
        "\n",
        "def preprocess_csv_files(input_path, output_path, train_file_path):\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    processed_file_names = []\n",
        "\n",
        "    for filename in os.listdir(input_path):\n",
        "        if not filename.endswith(\".csv\"):\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(input_path, filename)\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
        "            df.columns = df.columns.str.strip()\n",
        "\n",
        "            if len(df) >= 3:\n",
        "                metadata_df = df.iloc[-3:].copy()\n",
        "                dialogue_df = df.iloc[:-3].copy()\n",
        "            else:\n",
        "                metadata_df = pd.DataFrame()\n",
        "                dialogue_df = df.copy()\n",
        "\n",
        "            if \"Sub topic\" in dialogue_df.columns:\n",
        "                original_len = len(dialogue_df)\n",
        "                dialogue_df = dialogue_df[~dialogue_df[\"Sub topic\"].str.lower().eq(\"inactive\")]\n",
        "                removed = original_len - len(dialogue_df)\n",
        "                print(f\"{removed} 'inactive' rows removed in {filename}\")\n",
        "\n",
        "            if dialogue_df.empty:\n",
        "                print(f\"⚠️ No valid dialogue rows to process in: {filename}\")\n",
        "                continue\n",
        "\n",
        "            if \"Utterance\" not in dialogue_df.columns or \"Type\" not in dialogue_df.columns:\n",
        "                raise KeyError(f\"Required columns missing in file: {filename}\")\n",
        "\n",
        "            def process_row(row):\n",
        "                utterance = str(row[\"Utterance\"])\n",
        "                role = \"Patient\" if row[\"Type\"] == \"P\" else \"Therapist\"\n",
        "                return adjust_utterance(utterance, role)\n",
        "\n",
        "            dialogue_df[\"Utterance\"] = dialogue_df.apply(process_row, axis=1)\n",
        "\n",
        "            final_df = pd.concat([dialogue_df, metadata_df], ignore_index=True)\n",
        "\n",
        "            output_file = os.path.join(output_path, filename)\n",
        "            final_df.to_csv(output_file, index=False)\n",
        "\n",
        "            if os.path.exists(output_file):\n",
        "                print(f\"Saved: {output_file}\")\n",
        "                processed_file_names.append(os.path.splitext(filename)[0])\n",
        "            else:\n",
        "                print(f\"Failed to save file: {output_file}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "    # Write processed filenames\n",
        "    with open(train_file_path, \"w\") as f:\n",
        "        for name in processed_file_names:\n",
        "            f.write(name + \"\\n\")\n",
        "\n",
        "    print(f\"\\n Done! {len(processed_file_names)} files saved to: {output_path}\")\n",
        "    print(f\" Log saved to: {train_file_path}\")\n"
      ],
      "metadata": {
        "id": "3uX1pwHkkfcm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = \"/content/drive/MyDrive/MEMO_KDD_2022/Train\"\n",
        "output_path = \"/content/drive/MyDrive/MEMO_KDD_2022/Processed_new/training\"\n",
        "train = \"/content/drive/MyDrive/MEMO_KDD_2022/Processed_new/train.txt\"\n",
        "\n",
        "preprocess_csv_files(input_path, output_path, train)\n"
      ],
      "metadata": {
        "id": "h210E-dnkhET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = \"/content/drive/MyDrive/MEMO_KDD_2022/Validation\"\n",
        "output_path = \"/content/drive/MyDrive/MEMO_KDD_2022/Processed_new/validating\"\n",
        "train = \"/content/drive/MyDrive/MEMO_KDD_2022/Processed_new/val.txt\"\n",
        "\n",
        "preprocess_csv_files(input_path, output_path, train)\n"
      ],
      "metadata": {
        "id": "2HaWKgR7k_B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = \"/content/drive/MyDrive/MEMO_KDD_2022/Test\"\n",
        "output_path = \"/content/drive/MyDrive/MEMO_KDD_2022/Processed_new/testing\"\n",
        "train = \"/content/drive/MyDrive/MEMO_KDD_2022/Processed_new/test.txt\"\n",
        "\n",
        "preprocess_csv_files(input_path, output_path, train)\n"
      ],
      "metadata": {
        "id": "LxufFX1DoBli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABFNeGoXykh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}